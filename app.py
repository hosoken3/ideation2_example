# app.py ï¼ˆCSV+JSON èª­è¾¼ â†’ æ¤œç´¢ â†’ ãƒãƒƒãƒãƒ³ã‚°Top3 â†’ ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆ â†’ PRä½œæˆï¼‰
from __future__ import annotations
import io, os, sys, re, json as _json, datetime
from pathlib import Path
from typing import List, Dict
from zipfile import ZipFile

import pandas as pd
import streamlit as st
import chardet


import os
import pandas as pd
from PyPDF2 import PdfReader

# ===============================
# ğŸ”¹ 1. ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
# ===============================

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼èªè¨¼æƒ…å ±ï¼ˆUSERNAME_1 / PASSWORD_1 å½¢å¼ï¼‰---
def load_users_from_env(max_users=50):
    users = []
    for i in range(1, max_users + 1):
        u = os.getenv(f"USERNAME_{i}")
        p = os.getenv(f"PASSWORD_{i}")
        if u and p:
            users.append({"username": u, "password": p})
    return users

USERS = load_users_from_env()

# ------------------------------------------------------

# 3) ãƒ­ã‚°ã‚¤ãƒ³UIï¼ˆãƒšã‚¢ä¸€è‡´å¿…é ˆï¼‰

# ------------------------------------------------------

def login_ui():

    st.title("ğŸ” ãƒ­ã‚°ã‚¤ãƒ³")

    st.caption("â€» Render ã® Environment ã«è¨­å®šã—ãŸ USERNAME_i / PASSWORD_i ã®ãƒšã‚¢ã§èªè¨¼ã—ã¾ã™ã€‚")

    in_user = st.text_input("ãƒ¦ãƒ¼ã‚¶ãƒ¼å")

    in_pass = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")

    if st.button("ãƒ­ã‚°ã‚¤ãƒ³"):

        if any(u["username"] == in_user and u["password"] == in_pass for u in USERS):

            st.session_state["logged_in"] = True

            st.session_state["user_name"] = in_user

            st.success(f"ã‚ˆã†ã“ãã€{in_user} ã•ã‚“ï¼")

            st.rerun()

        else:

            st.error("ãƒ¦ãƒ¼ã‚¶ãƒ¼åã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé–“é•ã£ã¦ã„ã¾ã™ã€‚")

  

if "logged_in" not in st.session_state:

    st.session_state["logged_in"] = False

  

if not USERS:

    st.error("Environment ã« USERNAME_1/PASSWORD_1 å½¢å¼ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    st.stop()

  

if not st.session_state["logged_in"]:

    login_ui()

    st.stop()

  

# ãƒ­ã‚°ã‚¤ãƒ³å¾Œã‚µã‚¤ãƒ‰ãƒãƒ¼

with st.sidebar:

    st.success(f"ğŸ‘¤ ãƒ­ã‚°ã‚¤ãƒ³ä¸­ï¼š{st.session_state['user_name']}")

    if st.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):

        st.session_state.clear()

        st.rerun()


# ================== ãƒšãƒ¼ã‚¸è¨­å®š ==================
st.set_page_config(page_title="æŠ€è¡“ãƒ‹ãƒ¼ã‚º ãƒãƒƒãƒãƒ³ã‚° UI", layout="wide")
st.title("ğŸ§© æŠ€è¡“ãƒ‹ãƒ¼ã‚º ãƒãƒƒãƒãƒ³ã‚° UI")
st.sidebar.header("æ“ä½œ")

# ---- æ­£è¦åˆ—åï¼ˆã‚¢ãƒ—ãƒªå†…éƒ¨åï¼‰
COL_NO   = "ç•ªå·"
COL_COMP = "ä¼æ¥­å"
COL_NEWS = "æŠ€è¡“ãƒ‹ãƒ¼ã‚ºã®ãƒ‹ãƒ¥ãƒ¼ã‚¹å"
COL_CATL = "å¤§åˆ†é¡(é€£ç•ªä»˜ãé …ç›®å)"
COL_CATM = "ä¸­åˆ†é¡(é€£ç•ªä»˜ãé …ç›®å)"
COL_SUM  = "è¦ç´„"

# ---- ã‚»ãƒƒã‚·ãƒ§ãƒ³
ss = st.session_state
ss.setdefault("page", "select")            # select -> result -> idea
ss.setdefault("df_raw", None)
ss.setdefault("json_obj", None)
ss.setdefault("selection", set())
ss.setdefault("result_df", pd.DataFrame())
ss.setdefault("idea_df", pd.DataFrame())
ss.setdefault("idea_selection", set())     # â† PRå‡ºåŠ›ç”¨ã®è¡Œé¸æŠã‚’ä¿æŒ

# =========================================================
# å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================================================
def normalize_col(name: str) -> str:
    s = str(name).strip()
    s = s.replace("ã€€", " ").replace("ï¼ˆ", "(").replace("ï¼‰", ")")
    s = re.sub(r"\s+", " ", s)
    return s

@st.cache_data(show_spinner=False)
def load_dataframe(file) -> pd.DataFrame:
    raw = file.read()
    name = file.name.lower()
    if name.endswith(".csv"):
        enc = chardet.detect(raw).get("encoding") or "utf-8"
        for e in [enc, "utf-8", "cp932", "shift_jis", "utf-16", "utf-16le", "utf-16be"]:
            try:
                return pd.read_csv(io.BytesIO(raw), encoding=e)
            except Exception:
                continue
        raise RuntimeError("CSVã®æ–‡å­—ã‚³ãƒ¼ãƒ‰åˆ¤å®šã«å¤±æ•—ï¼ˆUTF-8/Shift-JIS/UTF-16ã‚’è©¦è¡Œï¼‰")
    return pd.read_excel(io.BytesIO(raw))

def auto_alias_columns(df: pd.DataFrame) -> pd.DataFrame:
    df = df.rename(columns={c: normalize_col(c) for c in df.columns})
    fix = {}
    if "å¤§åˆ†é¡" in df.columns: fix["å¤§åˆ†é¡"] = COL_CATL
    if "ä¸­åˆ†é¡" in df.columns: fix["ä¸­åˆ†é¡"] = COL_CATM
    if "å¤§åˆ†é¡ (é€£ç•ªä»˜ãé …ç›®å)" in df.columns: fix["å¤§åˆ†é¡ (é€£ç•ªä»˜ãé …ç›®å)"] = COL_CATL
    if "ä¸­åˆ†é¡ (é€£ç•ªä»˜ãé …ç›®å)" in df.columns: fix["ä¸­åˆ†é¡ (é€£ç•ªä»˜ãé …ç›®å)"] = COL_CATM
    if fix: df = df.rename(columns=fix)
    aliases = {
        COL_NO:   ["No","no","ID","Id","id","ç•ªå·"],
        COL_COMP: ["ä¼šç¤¾å","ä¼æ¥­","ç¤¾å","ä¼æ¥­å"],
        COL_NEWS: ["ãƒ‹ãƒ¥ãƒ¼ã‚¹å","æŠ€è¡“ãƒ‹ãƒ¼ã‚ºãƒ‹ãƒ¥ãƒ¼ã‚¹å","æŠ€è¡“ãƒ‹ãƒ¼ã‚ºã®ãƒ‹ãƒ¥ãƒ¼ã‚¹å"],
        COL_CATL: ["å¤§åˆ†é¡(é€£ç•ªä»˜ãé …ç›®å)","å¤§åˆ†é¡ï¼ˆé€£ç•ªä»˜ãé …ç›®åï¼‰"],
        COL_CATM: ["ä¸­åˆ†é¡(é€£ç•ªä»˜ãé …ç›®å)","ä¸­åˆ†é¡ï¼ˆé€£ç•ªä»˜ãé …ç›®åï¼‰"],
        COL_SUM:  ["ã‚µãƒãƒªãƒ¼","æ‘˜è¦","è¦æ—¨","è¦ç´„"],
    }
    cmap = {}
    for canon, cands in aliases.items():
        for c in cands:
            if c in df.columns:
                cmap[c] = canon
                break
    if cmap: df = df.rename(columns=cmap)
    return df

def enforce_types(df: pd.DataFrame) -> pd.DataFrame:
    for c in [COL_NO, COL_COMP, COL_NEWS, COL_CATL, COL_CATM, COL_SUM]:
        if c not in df.columns: df[c] = ""
        df[c] = df[c].astype(str)
    return df

# =========================================================
# å¤–éƒ¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆå‘¼ã³å‡ºã—ï¼ˆfind_similar / idea_generator / PRç”Ÿæˆï¼‰
# =========================================================
def run_find_similar_needs(df_selected: pd.DataFrame, params: dict) -> pd.DataFrame:
    """åŒãƒ•ã‚©ãƒ«ãƒ€ã® find_similar_needs.py ã® run(df_selected, params) ã‚’å®Ÿè¡Œ"""
    from importlib import import_module
    script = Path(__file__).with_name("find_similar_needs.py")
    if not script.exists():
        raise FileNotFoundError(f"{script} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    sys.path.insert(0, str(script.parent))
    try:
        mod = import_module(script.stem)
        if not hasattr(mod, "run"):
            raise RuntimeError("find_similar_needs.py ã« run(df_selected, params) ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return mod.run(df_selected, params)
    finally:
        try: sys.path.remove(str(script.parent))
        except ValueError: pass

def run_idea_generator(result_df: pd.DataFrame, params: dict | None = None) -> pd.DataFrame:
    """åŒãƒ•ã‚©ãƒ«ãƒ€ã® idea_generator_from_excel_openai.py ã® run(result_df, params) ã‚’å®Ÿè¡Œ"""
    from importlib import import_module
    script = Path(__file__).with_name("idea_generator_from_excel_openai.py")
    if not script.exists():
        raise FileNotFoundError(f"{script} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    sys.path.insert(0, str(script.parent))
    try:
        mod = import_module(script.stem)
        fn = getattr(mod, "run", None)
        if not callable(fn):
            raise RuntimeError("idea_generator_from_excel_openai.py ã« run(result_df, params) ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        out = fn(result_df, params or {})
        return out if isinstance(out, pd.DataFrame) else pd.DataFrame(out)
    finally:
        try: sys.path.remove(str(script.parent))
        except ValueError: pass

# ---- PRç”Ÿæˆï¼ˆæ·»ä»˜PGã‚’å†…éƒ¨å®Ÿè¡Œï¼‰
def _sanitize_filename(name: str, maxlen: int = 80) -> str:
    s = (name or "").strip()
    s = re.sub(r'[\\/:*?"<>|]', '_', s)
    s = re.sub(r'\s+', ' ', s)
    return (s[:maxlen]).rstrip(' .')

def run_press_release_from_ideas(idea_df: pd.DataFrame,
                                 rows: list[int] | None = None,
                                 refs_dir: Path | None = None,
                                 outdir: Path | None = None,
                                 model: str = "o3-2025-04-16") -> Dict[str, bytes]:
    """
    idea_df ã®é¸æŠè¡Œã‹ã‚‰ PR æ–‡æ›¸(.docx)ã‚’ä½œæˆã—ã€{ãƒ•ã‚¡ã‚¤ãƒ«å: ãƒã‚¤ãƒˆåˆ—} ã‚’è¿”ã™ã€‚
    - rows: 1å§‹ã¾ã‚Šã®è¡Œç•ªå·ï¼ˆæœªæŒ‡å®šãªã‚‰å…¨è¡Œï¼‰
    - refs_dir: å‚ç…§PDFãƒ•ã‚©ãƒ«ãƒ€ï¼ˆçœç•¥æ™‚ã¯ app.py ã¨åŒéšå±¤ã®ã€Œãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ä½œæˆã€ï¼‰
    - outdir: ç”Ÿæˆå…ˆï¼ˆæŒ‡å®šã™ã‚Œã°å®Ÿãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä¿å­˜ï¼‰
    """
    if idea_df is None or idea_df.empty:
        return {}

    from importlib import import_module
    mod_path = Path(__file__).with_name("batch_pr_from_excel_docx.py")
    if not mod_path.exists():
        raise FileNotFoundError(f"{mod_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    sys.path.insert(0, str(mod_path.parent))
    try:
        pr = import_module(mod_path.stem)
    finally:
        try: sys.path.remove(str(mod_path.parent))
        except ValueError: pass

    # å‚ç…§PDFï¼ˆå­˜åœ¨ã™ã‚Œã°ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨ï¼‰
    refs_dir = refs_dir or Path(__file__).with_name("ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ä½œæˆ")
    style_text = pr.prepare_style_corpus(refs_dir) if refs_dir.exists() else None

    if not rows:
        rows = list(range(1, len(idea_df) + 1))
    valid_idx = [i for i in rows if 1 <= i <= len(idea_df)]
    if not valid_idx:
        return {}

    if outdir:
        outdir.mkdir(parents=True, exist_ok=True)

    today = datetime.date.today()
    date_jp = f"{today.year}å¹´{today.month:02d}æœˆ{today.day:02d}æ—¥ï¼ˆä½œæˆæ—¥ï¼‰"

    # åˆ—åãƒãƒƒãƒ—ï¼ˆå†…éƒ¨â†’PRå´ï¼‰
    df = idea_df.rename(columns={
        "å…¥åŠ›æŠ€è¡“ãƒ‹ãƒ¼ã‚º": "å…¥åŠ›_æŠ€è¡“ãƒ‹ãƒ¼ã‚º",
        "å…¥åŠ›è£½å“ã‚·ãƒ¼ã‚º": "å…¥åŠ›_è£½å“ã‚·ãƒ¼ã‚º",
    }).copy()

    outputs: Dict[str, bytes] = {}
    for i in valid_idx:
        row = df.iloc[i - 1]
        idea_name = str(row.get("ã‚¢ã‚¤ãƒ‡ã‚¢å", f"idea_{i}")).strip() or f"idea_{i}"
        fname = _sanitize_filename(idea_name) + ".docx"

        fields = pr.build_fields_from_row(row)
        md = pr.call_openai(model, fields, date_jp, style_text)

        # ä¿å­˜ & ãƒã‚¤ãƒˆåŒ–
        if outdir:
            out_path = outdir / fname
            pr.mdish_to_docx(md, out_path)
            outputs[fname] = out_path.read_bytes()
        else:
            tmp = Path.cwd() / fname
            pr.mdish_to_docx(md, tmp)
            outputs[fname] = tmp.read_bytes()
            tmp.unlink(missing_ok=True)

    return outputs

# =========================================================
# ç”»é¢: é¸æŠãƒ»æ¤œç´¢
# =========================================================
def page_select():
    st.subheader("1) å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­è¾¼ï¼ˆè‡ªå‹•/æ‰‹å‹•ï¼‰")

    # è‡ªå‹•èª­è¾¼ï¼ˆåŒãƒ•ã‚©ãƒ«ãƒ€ï¼‰
    #default_csv = Path(__file__).with_name("/etc/secrets/tech_needs_classification.csv")
    default_csv = Path("display/tech_needs_classification.csv")
    default_json = Path("display/excel_analysis.json")

    if ss.df_raw is None and default_csv.exists():
        try:
            df = pd.read_csv(default_csv, encoding="utf-8-sig")
        except Exception:
            df = pd.read_csv(default_csv, encoding="cp932", errors="ignore")
        df = enforce_types(auto_alias_columns(df))
        ss.df_raw = df
        st.info(f"CSV è‡ªå‹•èª­è¾¼: {default_csv.name}")

    if ss.json_obj is None and default_json.exists():
        try:
            ss.json_obj = _json.loads(default_json.read_text(encoding="utf-8"))
            st.info(f"JSON è‡ªå‹•èª­è¾¼: {default_json.name}")
        except Exception as e:
            st.warning(f"JSON è‡ªå‹•èª­è¾¼å¤±æ•—: {e}")

    # æ‰‹å‹•ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    up_csv = st.file_uploader("CSV/Excel ã‚’é¸æŠï¼ˆä»»æ„ï¼šè‡ªå‹•èª­è¾¼æ¸ˆã¿ãªã‚‰ä¸è¦ï¼‰", type=["csv","xlsx","xls"])
    if up_csv:
        try:
            df = enforce_types(auto_alias_columns(load_dataframe(up_csv)))
            ss.df_raw = df
            st.success(f"èª­è¾¼å®Œäº†: {df.shape[0]}è¡Œ Ã— {df.shape[1]}åˆ—")
        except Exception as e:
            st.error(f"èª­è¾¼ã‚¨ãƒ©ãƒ¼: {e}")

    up_json = st.file_uploader("JSONï¼ˆexcel_analysis.jsonãƒ»ä»»æ„ï¼‰", type=["json"])
    if up_json:
        try:
            ss.json_obj = _json.load(io.TextIOWrapper(up_json, encoding="utf-8"))
            st.success("JSON èª­è¾¼å®Œäº†")
        except Exception as e:
            st.error(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}")

    if ss.df_raw is None:
        st.stop()

    # æ¤œç´¢UI
    st.subheader("2) æ¤œç´¢æ¡ä»¶")
    df = ss.df_raw.copy()
    c1, c2, c3 = st.columns([2,2,2])
    comp = c1.selectbox("ä¼æ¥­åï¼š", ["(ã™ã¹ã¦)"] + sorted(df[COL_COMP].dropna().unique().tolist()), index=0)
    catL = c2.selectbox("å¤§åˆ†é¡ï¼š", ["(ã™ã¹ã¦)"] + sorted(df[COL_CATL].dropna().unique().tolist()), index=0)
    mids = sorted(df[df[COL_CATL] == catL][COL_CATM].dropna().unique().tolist()) if catL != "(ã™ã¹ã¦)" \
           else sorted(df[COL_CATM].dropna().unique().tolist())
    catM = c3.selectbox("ä¸­åˆ†é¡ï¼š", ["(ã™ã¹ã¦)"] + mids, index=0)

    c4, c5, c6 = st.columns([3,1,1])
    q = c4.text_input("ãƒ‹ãƒ¥ãƒ¼ã‚¹åï¼š", value="", placeholder="ï¼ˆæ›–æ˜§æ¤œç´¢ï¼‰")
    do_search = c5.button("æ¤œç´¢")
    do_clear  = c6.button("ã‚¯ãƒªã‚¢")

    if do_clear:
        comp = catL = catM = "(ã™ã¹ã¦)"; q = ""

    flt = df.copy()
    if comp != "(ã™ã¹ã¦)": flt = flt[flt[COL_COMP] == comp]
    if catL != "(ã™ã¹ã¦)": flt = flt[flt[COL_CATL] == catL]
    if catM != "(ã™ã¹ã¦)": flt = flt[flt[COL_CATM] == catM]
    if do_search and q.strip():
        flt = flt[flt[COL_NEWS].str.contains(q.strip(), case=False, na=False)]

    # è¡Œé¸æŠ
    st.subheader("3) å¯¾è±¡ã®è¡Œã‚’é¸æŠ")
    view_cols = [COL_NO, COL_COMP, COL_NEWS, COL_CATL, COL_CATM, COL_SUM]
    v = flt[view_cols].copy()
    v.insert(0, "é¸æŠ", v[COL_NO].astype(str).isin(ss.selection))
    edited = st.data_editor(
        v, hide_index=True, use_container_width=True, num_rows="fixed",
        column_config={"é¸æŠ": st.column_config.CheckboxColumn("", help="ã“ã®è¡Œã‚’é¸æŠ")}
    )
    ss.selection = set(edited[edited["é¸æŠ"]][COL_NO].astype(str).tolist())
    st.caption(f"é¸æŠä»¶æ•°ï¼š{len(ss.selection)}")

    # å®Ÿè¡Œ
    if st.button("ğŸ” ãƒãƒƒãƒãƒ³ã‚°å®Ÿè¡Œï¼ˆTop3ï¼‰", type="primary"):
        if not ss.selection:
            st.warning("å…ˆã«è¡Œã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚"); st.stop()
        df_selected = df[df[COL_NO].astype(str).isin(list(ss.selection))].copy()
        with st.spinner("CSV+JSON ã‚’ç”¨ã„ã¦ãƒãƒƒãƒãƒ³ã‚°ä¸­â€¦"):
            res = run_find_similar_needs(
                df_selected,
                params={
                    "df_all": ss.df_raw,
                    "json_obj": ss.json_obj,
                    "top_n": 3,  # Top3å›ºå®š
                    "target_exclude_companies": ["ãƒ­ãƒ¼ãƒ "],  # ã‚¯ã‚¨ãƒª=ãƒ­ãƒ¼ãƒ ä»¥å¤–
                    "cand_include_companies": ["ãƒ­ãƒ¼ãƒ "],   # ã‚³ãƒ¼ãƒ‘ã‚¹=ãƒ­ãƒ¼ãƒ ã®ã¿
                    "exclude_same_company": True,
                }
            )
        # å¿µã®ãŸã‚å„å…ƒãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã¤ãTop3ã‚’å¼·åˆ¶
        res = (res.sort_values("similarity", ascending=False)
                 .groupby("å…ƒæŠ€è¡“ãƒ‹ãƒ¼ã‚ºã®ãƒ‹ãƒ¥ãƒ¼ã‚¹å", as_index=False, sort=False)
                 .head(3).reset_index(drop=True))
        # ç•ªå·=è¡Œç•ªå·ã«æŒ¯ã‚Šç›´ã—
        res[COL_NO] = (pd.Series(range(1, len(res)+1))).astype(str)
        ss.result_df = res
        ss.page = "result"; st.rerun()

# =========================================================
# ç”»é¢: çµæœï¼ˆTop3ï¼‰
# =========================================================
def page_result():
    st.subheader("ãƒãƒƒãƒãƒ³ã‚°çµæœï¼ˆTop3ï¼‰")
    df = ss.result_df.copy()
    st.dataframe(df, use_container_width=True, height=560)

    c1, c2, c3 = st.columns([2,1,1])
    c1.download_button("CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                       data=df.to_csv(index=False).encode("utf-8-sig"),
                       file_name="matching_result.csv", mime="text/csv")
    back = c2.button("â† æˆ»ã‚‹")
    go_idea = c3.button("ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆ â–¶", type="primary")

    if back:
        ss.page = "select"; st.rerun()

    if go_idea:
        try:
            with st.spinner("ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆä¸­â€¦"):
                ss.idea_df = run_idea_generator(df, params={"max_ideas_per_need": 3})
            ss.page = "idea"; st.rerun()
        except Exception as e:
            import traceback
            st.error("ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            st.exception(e); st.code(traceback.format_exc())

# =========================================================
# ç”»é¢: ã‚¢ã‚¤ãƒ‡ã‚¢ä¸€è¦§ ï¼‹ ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ä½œæˆï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹é¸æŠï¼‰
# =========================================================
def page_idea():
    st.subheader("ã‚¢ã‚¤ãƒ‡ã‚¢ä¸€è¦§ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰")
    df = ss.idea_df.copy()
    if df.empty:
        st.info("ã‚¢ã‚¤ãƒ‡ã‚¢ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ã™ã€‚")
        if st.button("â† çµæœã«æˆ»ã‚‹"):
            ss.page = "result"; st.rerun()
        return

    # è¡¨ç¤ºï¼š1å§‹ã¾ã‚Šã®è¡Œç•ªå· & ãƒã‚§ãƒƒã‚¯åˆ—
    df_view = df.copy()
    df_view.insert(0, "è¡Œç•ªå·", range(1, len(df_view) + 1))
    pre_checked = df_view["è¡Œç•ªå·"].astype(int).isin(ss.idea_selection)
    df_view.insert(0, "é¸æŠ", pre_checked)

    show_cols = [
        "é¸æŠ", "è¡Œç•ªå·", "ç•ªå·", "å…ƒã‚·ãƒ¼ãƒˆå",
        "å…¥åŠ›æŠ€è¡“ãƒ‹ãƒ¼ã‚º", "å…¥åŠ›è£½å“ã‚·ãƒ¼ã‚º",
        "ã‚¢ã‚¤ãƒ‡ã‚¢å", "ã‚¢ã‚¤ãƒ‡ã‚¢ã®åˆ‡ã‚Šå£",
        "å…·ä½“çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³", "ã‚¢ã‚¤ãƒ‡ã‚¢å‰µå‡ºã®ãƒ—ãƒ­ã‚»ã‚¹",
    ]
    show_cols = [c for c in show_cols if c in df_view.columns]

    st.markdown(
        "<div style='text-align:right; margin: 6px 0;'>"
        "<span style='font-size:20px; font-weight:700; "
        "padding:6px 18px; border:2px solid #333; border-radius:6px;'>ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ</span>"
        "</div>", unsafe_allow_html=True
    )

    edited = st.data_editor(
        df_view[show_cols],
        hide_index=True,
        use_container_width=True,
        num_rows="fixed",
        column_config={"é¸æŠ": st.column_config.CheckboxColumn("")},
        height=520,
    )

    selected_rows = edited.loc[edited["é¸æŠ"], "è¡Œç•ªå·"].astype(int).tolist()
    ss.idea_selection = set(selected_rows)

    # å‚ç…§PDFãƒ•ã‚©ãƒ«ãƒ€ï¼ˆapp.py ã¨åŒéšå±¤ã®ã€Œãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ä½œæˆ/ã€ï¼‰
    ref_dir = Path(__file__).with_name("ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ä½œæˆ")
    if ref_dir.exists():
        st.caption(f"å‚ç…§PDFãƒ•ã‚©ãƒ«ãƒ€ï¼š{ref_dir}ï¼ˆæ¤œå‡º â†’ ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨ï¼‰")
    else:
        st.caption("å‚ç…§PDFãƒ•ã‚©ãƒ«ãƒ€ï¼šæœªæ¤œå‡ºï¼ˆã‚¹ã‚¿ã‚¤ãƒ«å‚ç…§ãªã—ã§ä½œæˆï¼‰")

    c1, c2, c3 = st.columns([2,1,2])
    do_make = c1.button("ğŸ“° é¸æŠã—ãŸè¡Œã ã‘ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ä½œæˆ", type="primary")
    back    = c2.button("â† çµæœã«æˆ»ã‚‹")
    c3.download_button(
        "ã‚¢ã‚¤ãƒ‡ã‚¢CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=edited.drop(columns=["é¸æŠ"]).to_csv(index=False).encode("utf-8-sig"),
        file_name="ideas.csv", mime="text/csv"
    )

    if do_make:
        if not selected_rows:
            st.warning("å…ˆã«ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã§å‡ºåŠ›å¯¾è±¡ã®è¡Œã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        else:
            with st.spinner("ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹ã‚’ç”Ÿæˆä¸­..."):
                files = run_press_release_from_ideas(
                    idea_df=df,                        # å…ƒã®ã‚¢ã‚¤ãƒ‡ã‚¢DF
                    rows=selected_rows,                # â† é¸æŠã—ãŸè¡Œã ã‘
                    refs_dir=(ref_dir if ref_dir.exists() else None),
                    outdir=None,
                    model="o3-2025-04-16"
                )
            if not files:
                st.warning("ç”Ÿæˆå¯¾è±¡ãŒã‚ã‚Šã¾ã›ã‚“ or ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            else:
                st.success(f"{len(files)} ä»¶ã® .docx ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")
                # å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åï¼ã‚¢ã‚¤ãƒ‡ã‚¢åï¼‰
                st.markdown("**å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**")
                for name, data in files.items():
                    st.download_button(
                        f"â¬‡ {name}", data=data, file_name=name,
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
                # ZIP ä¸€æ‹¬
                mem = io.BytesIO()
                with ZipFile(mem, mode="w") as zf:
                    for name, data in files.items():
                        zf.writestr(name, data)
                mem.seek(0)
                st.download_button("ğŸ“¦ ZIPã§ä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=mem.read(),
                                   file_name="press_releases.zip", mime="application/zip")

    if back:
        ss.page = "result"; st.rerun()

# =========================================================
# ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
# =========================================================
if ss.page == "select":
    page_select()
elif ss.page == "result":
    page_result()
else:
    page_idea()
